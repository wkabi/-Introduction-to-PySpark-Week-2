{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 9\n\n# Create the DataFrame flights\nflights = spark.table(\"flights\")\n\n# Show the head\nprint(flights.show())\n\n# Add duration_hrs\nflights = flights.withColumn(\"duration_hrs\",flights.air_time/60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 10\n\n# Filter flights by passing a string\nlong_flights1 = flights.filter(\"distance>1000\")\n\n# Filter flights by passing a column of boolean values\nlong_flights2 = flights.filter(flights.distance>1000)\n\n# Print the data to check they're equal\nprint(long_flights1.show())\nprint(long_flights2.show())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 11\n\n# Select the first set of columns\nselected1 = flights.select(\"tailnum\",\"origin\",\"dest\")\n\n# Select the second set of columns\ntemp = flights.select(flights.origin,flights.dest,flights.carrier)\n\n# Define first filter\nfilterA = flights.origin == \"SEA\"\n\n# Define second filter\nfilterB = flights.dest == \"PDX\"\n\n# Filter the data, first by filterA then by filterB\nselected2 = temp.filter(filterA).filter(filterB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 12\n\n# Define avg_speed\navg_speed = (flights.distance/(flights.air_time/60)).alias(\"avg_speed\")\n\n# Select the correct columns\nspeed1 = flights.select(\"origin\", \"dest\", \"tailnum\", avg_speed)\n\n# Create the same table using a SQL expression\nspeed2 = flights.selectExpr(\"origin\", \"dest\", \"tailnum\", \"distance/(air_time/60) as avg_speed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 13\n\n# Find the shortest flight from PDX in terms of distance\nflights.filter(flights.origin=='PDX').groupBy().min(\"distance\").show()\n\n# Find the longest flight from SEA in terms of air time\nflights.filter(flights.origin=='SEA').groupBy().max(\"air_time\").show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 14\n\n# Average duration of Delta flights\nflights.filter(flights.origin==\"SEA\").filter(flights.carrier==\"DL\").groupBy().avg(\"air_time\").show()\n\n# Total hours in the air\nflights.withColumn(\"duration_hrs\", flights.air_time/60).groupBy().sum(\"duration_hrs\").show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 15\n\n# Group by tailnum\nby_plane = flights.groupBy(\"tailnum\")\n\n# Number of flights each plane made\nby_plane.count().show()\n\n# Group by origin\nby_origin = flights.groupBy(\"origin\")\n\n# Average duration of flights from PDX and SEA\nby_origin.avg(\"air_time\").show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 16\n\n# Import pyspark.sql.functions as F\nimport pyspark.sql.functions as F\n\n# Group by month and dest\nby_month_dest = flights.groupBy(\"month\",\"dest\")\n\n# Average departure delay by month and destination\nby_month_dest.avg(\"dep_delay\").show()\n\n# Standard deviation of departure delay\nby_month_dest.agg(F.stddev(\"dep_delay\")).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 17\n\n# Examine the data\nprint(airports.show())\n\n# Rename the faa column\nairports = airports.withColumnRenamed(\"faa\", \"dest\")\n\n# Join the DataFrames\nflights_with_airports = flights.join(airports,on='dest',how=\"leftouter\")\n\n# Examine the new DataFrame\nprint(flights_with_airports.show())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}